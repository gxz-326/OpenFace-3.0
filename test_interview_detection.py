#!/usr/bin/env python3
"""
é¢è°ˆæ£€æµ‹ç³»ç»Ÿæµ‹è¯•è„šæœ¬
éªŒè¯æ‰€æœ‰ç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import unittest
import torch
import numpy as np
from PIL import Image
import tempfile
import shutil

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from interview_detection import (
        InterviewDetectionModel,
        YFPFacialParalysisDataset,
        calculate_metrics,
        image_transforms
    )
    IMPORTS_AVAILABLE = True
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    IMPORTS_AVAILABLE = False


class TestInterviewDetection(unittest.TestCase):
    """é¢è°ˆæ£€æµ‹ç³»ç»Ÿæµ‹è¯•ç±»"""
    
    @classmethod
    def setUpClass(cls):
        """æµ‹è¯•ç±»åˆå§‹åŒ–"""
        if not IMPORTS_AVAILABLE:
            cls.skipTest("æ— æ³•å¯¼å…¥å¿…è¦çš„æ¨¡å—")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        cls.temp_dir = tempfile.mkdtemp()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
        cls.create_test_dataset()
        
        # è®¾ç½®è®¾å¤‡
        cls.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    @classmethod
    def tearDownClass(cls):
        """æµ‹è¯•ç±»æ¸…ç†"""
        # åˆ é™¤ä¸´æ—¶ç›®å½•
        if os.path.exists(cls.temp_dir):
            shutil.rmtree(cls.temp_dir)
    
    @classmethod
    def create_test_dataset(cls):
        """åˆ›å»ºæµ‹è¯•æ•°æ®é›†"""
        # åˆ›å»ºç›®å½•ç»“æ„
        normal_dir = os.path.join(cls.temp_dir, 'normal')
        paralysis_dir = os.path.join(cls.temp_dir, 'paralysis')
        os.makedirs(normal_dir)
        os.makedirs(paralysis_dir)
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        for i in range(5):
            # æ­£å¸¸å›¾åƒ
            img_array = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)
            image = Image.fromarray(img_array)
            image.save(os.path.join(normal_dir, f'normal_{i:03d}.jpg'))
            
            # é¢ç˜«å›¾åƒ
            img_array = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)
            image = Image.fromarray(img_array)
            image.save(os.path.join(paralysis_dir, f'paralysis_{i:03d}.jpg'))
    
    def test_dataset_creation(self):
        """æµ‹è¯•æ•°æ®é›†åˆ›å»º"""
        dataset = YFPFacialParalysisDataset(self.temp_dir, transform=image_transforms)
        
        # æ£€æŸ¥æ•°æ®é›†å¤§å°
        self.assertEqual(len(dataset), 10)
        
        # æ£€æŸ¥æ•°æ®åŠ è½½
        image, label = dataset[0]
        self.assertIsInstance(image, torch.Tensor)
        self.assertIsInstance(label, torch.Tensor)
        self.assertEqual(image.shape, (3, 224, 224))
        self.assertIn(label.item(), [0, 1])
    
    def test_model_creation(self):
        """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
        model = InterviewDetectionModel()
        
        # æ£€æŸ¥æ¨¡å‹ç»“æ„
        self.assertIsInstance(model, torch.nn.Module)
        
        # æ£€æŸ¥æ¨¡å‹è¾“å‡º
        dummy_input = torch.randn(1, 3, 224, 224)
        interview_output, emotion_output, gaze_output, au_output = model(dummy_input)
        
        self.assertEqual(interview_output.shape, (1, 2))  # äºŒåˆ†ç±»
        self.assertEqual(emotion_output.shape, (1, 8))   # 8ç±»æƒ…æ„Ÿ
        self.assertEqual(gaze_output.shape, (1, 2))     # 2D gaze
        self.assertEqual(au_output.shape, (1, 8))       # 8ä¸ªAU
    
    def test_metrics_calculation(self):
        """æµ‹è¯•æŒ‡æ ‡è®¡ç®—"""
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        true_labels = np.array([0, 0, 1, 1, 0, 1, 0, 1])
        pred_labels = np.array([0, 0, 1, 0, 0, 1, 1, 1])
        
        metrics = calculate_metrics(true_labels, pred_labels)
        
        # æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦å­˜åœ¨ä¸”åœ¨åˆç†èŒƒå›´å†…
        required_metrics = ['accuracy', 'f1_score', 'precision', 'recall', 'specificity']
        for metric in required_metrics:
            self.assertIn(metric, metrics)
            self.assertGreaterEqual(metrics[metric], 0.0)
            self.assertLessEqual(metrics[metric], 1.0)
        
        # æ£€æŸ¥æ··æ·†çŸ©é˜µ
        self.assertIn('confusion_matrix', metrics)
        self.assertEqual(len(metrics['confusion_matrix']), 2)
        self.assertEqual(len(metrics['confusion_matrix'][0]), 2)
    
    def test_training_step(self):
        """æµ‹è¯•è®­ç»ƒæ­¥éª¤"""
        model = InterviewDetectionModel()
        model.to(self.device)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        dummy_input = torch.randn(4, 3, 224, 224).to(self.device)
        dummy_labels = torch.randint(0, 2, (4,)).to(self.device)
        
        # å‰å‘ä¼ æ’­
        interview_output, _, _, _ = model(dummy_input)
        
        # è®¡ç®—æŸå¤±
        criterion = torch.nn.CrossEntropyLoss()
        loss = criterion(interview_output, dummy_labels)
        
        # åå‘ä¼ æ’­
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºæ•°å€¼
        self.assertFalse(torch.isnan(loss))
        self.assertFalse(torch.isinf(loss))
        self.assertGreater(loss.item(), 0)
    
    def test_prediction(self):
        """æµ‹è¯•é¢„æµ‹åŠŸèƒ½"""
        model = InterviewDetectionModel()
        model.to(self.device)
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        dummy_input = torch.randn(1, 3, 224, 224).to(self.device)
        
        with torch.no_grad():
            interview_output, _, _, _ = model(dummy_input)
            
            # è·å–é¢„æµ‹ç»“æœ
            probabilities = torch.softmax(interview_output, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1)
            confidence = probabilities[0, predicted_class]
            
            # æ£€æŸ¥é¢„æµ‹ç»“æœ
            self.assertIn(predicted_class.item(), [0, 1])
            self.assertGreaterEqual(confidence.item(), 0.0)
            self.assertLessEqual(confidence.item(), 1.0)
    
    def test_data_loading(self):
        """æµ‹è¯•æ•°æ®åŠ è½½"""
        dataset = YFPFacialParalysisDataset(self.temp_dir, transform=image_transforms)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        for images, labels in dataloader:
            self.assertEqual(images.shape[0], 2)  # batch size
            self.assertEqual(images.shape[1:], (3, 224, 224))  # image shape
            self.assertEqual(labels.shape[0], 2)  # batch size
            break  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªbatch


class TestIntegration(unittest.TestCase):
    """é›†æˆæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        if not IMPORTS_AVAILABLE:
            self.skipTest("æ— æ³•å¯¼å…¥å¿…è¦çš„æ¨¡å—")
        
        self.temp_dir = tempfile.mkdtemp()
        self.create_test_dataset()
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†"""
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def create_test_dataset(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®é›†"""
        normal_dir = os.path.join(self.temp_dir, 'normal')
        paralysis_dir = os.path.join(self.temp_dir, 'paralysis')
        os.makedirs(normal_dir)
        os.makedirs(paralysis_dir)
        
        for i in range(3):
            img_array = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)
            image = Image.fromarray(img_array)
            image.save(os.path.join(normal_dir, f'normal_{i:03d}.jpg'))
            image.save(os.path.join(paralysis_dir, f'paralysis_{i:03d}.jpg'))
    
    def test_full_pipeline(self):
        """æµ‹è¯•å®Œæ•´æµç¨‹"""
        # 1. åˆ›å»ºæ•°æ®é›†
        dataset = YFPFacialParalysisDataset(self.temp_dir, transform=image_transforms)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)
        
        # 2. åˆ›å»ºæ¨¡å‹
        model = InterviewDetectionModel()
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        
        # 3. è®­ç»ƒå‡ ä¸ªæ­¥éª¤
        criterion = torch.nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        
        model.train()
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            interview_output, _, _, _ = model(images)
            loss = criterion(interview_output, labels)
            loss.backward()
            optimizer.step()
        
        # 4. è¯„ä¼°
        model.eval()
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for images, labels in dataloader:
                images, labels = images.to(device), labels.to(device)
                interview_output, _, _, _ = model(images)
                preds = torch.argmax(interview_output, dim=1)
                
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        # 5. è®¡ç®—æŒ‡æ ‡
        metrics = calculate_metrics(all_labels, all_preds)
        
        # æ£€æŸ¥æµç¨‹æ˜¯å¦å®Œæˆ
        self.assertIn('accuracy', metrics)
        self.assertGreaterEqual(metrics['accuracy'], 0.0)


def run_basic_tests():
    """è¿è¡ŒåŸºæœ¬æµ‹è¯•"""
    print("è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•...")
    print("="*50)
    
    # æ£€æŸ¥å¯¼å…¥
    if not IMPORTS_AVAILABLE:
        print("âŒ å¯¼å…¥æµ‹è¯•å¤±è´¥ - æ— æ³•å¯¼å…¥å¿…è¦æ¨¡å—")
        return False
    
    print("âœ… å¯¼å…¥æµ‹è¯•é€šè¿‡")
    
    # æ£€æŸ¥PyTorch
    try:
        x = torch.randn(1, 3, 224, 224)
        print("âœ… PyTorchåŸºæœ¬æ“ä½œæµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ PyTorchæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æ£€æŸ¥å…¶ä»–ä¾èµ–
    try:
        import sklearn
        import matplotlib
        import seaborn
        print("âœ… å…¶ä»–ä¾èµ–åŒ…æµ‹è¯•é€šè¿‡")
    except ImportError as e:
        print(f"âŒ ä¾èµ–åŒ…æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("é¢è°ˆæ£€æµ‹ç³»ç»Ÿæµ‹è¯•")
    print("Interview Detection System Tests")
    print("="*60)
    
    # è¿è¡ŒåŸºæœ¬æµ‹è¯•
    if not run_basic_tests():
        print("\nåŸºæœ¬æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–åŒ…å®‰è£…")
        return
    
    print("\nè¿è¡Œå•å…ƒæµ‹è¯•...")
    print("="*50)
    
    # è¿è¡Œå•å…ƒæµ‹è¯•
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    suite.addTests(loader.loadTestsFromTestCase(TestInterviewDetection))
    suite.addTests(loader.loadTestsFromTestCase(TestIntegration))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    if result.wasSuccessful():
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        print("ğŸ‰ All tests passed! System is working correctly.")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        print("âŒ Some tests failed, please check the error messages.")
        print(f"å¤±è´¥çš„æµ‹è¯•æ•°é‡: {len(result.failures)}")
        print(f"é”™è¯¯çš„æµ‹è¯•æ•°é‡: {len(result.errors)}")
    
    print("="*60)
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)